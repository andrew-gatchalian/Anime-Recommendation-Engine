{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH2P02yVSB2G"
      },
      "source": [
        "# BANA 212 - Final Project\n",
        "### Anime Recommendations using Machine Learning (based on user ratings from MyAnimeList.com)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATA PRE-PROCESSING (Part 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wmNRULi3vXX",
        "outputId": "5ce11a09-9a3b-4ed3-86a6-68c05ce257e7"
      },
      "outputs": [],
      "source": [
        "pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sB8Gn4gd35A0"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.1 Pull list of all Animes on the site (updated 10/25)\n",
        "\n",
        "*   There was missing values for some of the items we pulled - added if statement that fills column with -1 if missing value\n",
        "* changed dataframe \"studio\" to \"studios\" for continuity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CLIENT_ID = '018269e286b49a7ca078f74376d45377'\n",
        "\n",
        "# Initialize an empty list to store all the data\n",
        "all_anime_list = []\n",
        "df_AAL = pd.DataFrame(columns=['anime_id', 'title', 'mean', 'genres', 'studios', 'synopsis', 'media_type', 'num_episodes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#update this (ex. 10400 â€“ 20800)\n",
        "anime_id_start = 0\n",
        "anime_id_limit = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for anime_id in range(anime_id_start,anime_id_limit):\n",
        "  url = f'https://api.myanimelist.net/v2/anime/{anime_id}?fields=id,title,start_date,end_date,synopsis,mean,rank,popularity,num_list_users,num_scoring_users,media_type,genres,num_episodes,studios'\n",
        "\n",
        "  response = requests.get(url, headers = {\n",
        "      'X-MAL-CLIENT-ID': CLIENT_ID\n",
        "      })\n",
        "\n",
        "  if response.status_code == 404: #if anime id doesnt exit, skip\n",
        "    print(\"404 anime id not found\")\n",
        "    continue\n",
        "\n",
        "  response.raise_for_status()\n",
        "  anime_list = response.json()\n",
        "  response.close()\n",
        "  print(anime_list)\n",
        "\n",
        "\n",
        "  anime_entry = anime_list\n",
        "  all_anime_list.extend(anime_entry)\n",
        "\n",
        "  anime_data = [{\n",
        "        'anime_id': anime_entry['id'] if 'id' in anime_entry else -1,\n",
        "        'title': anime_entry['title'] if 'title' in anime_entry else -1,\n",
        "        'mean': anime_entry['mean'] if 'mean' in anime_entry else -1,\n",
        "        'genres': [genre['name'] for genre in anime_entry['genres']] if 'genres' in anime_entry else -1,\n",
        "        'studios': [studios['name'] for studios in anime_entry['studios']] if 'studios' in anime_entry else -1,\n",
        "        'synopsis': anime_entry['synopsis'] if 'synopsis' in anime_entry else -1,\n",
        "        'media_type': anime_entry['media_type'] if 'media_type' in anime_entry else -1,\n",
        "        'num_episodes': anime_entry['num_episodes'] if 'num_episodes' in anime_entry else -1\n",
        "    }]\n",
        "\n",
        "\n",
        "  df_AAL = df_AAL.append(pd.DataFrame(anime_data))\n",
        "\n",
        "  time.sleep(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_AAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to CSV\n",
        "df_AAL.to_csv('all_anime_list.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rD2QU4uHJlO"
      },
      "source": [
        "# 1.2 MyAnimeList Username Web Scraper\n",
        "\n",
        "Before fetching a user's ratings, we first need a list of users!\n",
        "\n",
        "To create a list of users we will scrape the MyAnimeList webpage using Python and store the names in a dataframe & CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9fW4QVlHtHc"
      },
      "outputs": [],
      "source": [
        "#initialize df\n",
        "user_list = pd.DataFrame(columns=[\"username\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOKrH0CO4WDQ"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# The URL to fetch\n",
        "url = \"https://myanimelist.net/users.php?lucky=1\"\n",
        "\n",
        "# Minimum number of unique usernames you want to collect\n",
        "minimum_user_count = 50000\n",
        "\n",
        "# Initialize a set to store unique usernames\n",
        "unique_usernames = set()\n",
        "\n",
        "while len(unique_usernames) < minimum_user_count:\n",
        "    # Send an HTTP GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract usernames from the page\n",
        "        usernames = soup.find_all('a', href=lambda href: href and '/profile/' in href)\n",
        "\n",
        "        # Add the usernames to the set to keep them unique\n",
        "        unique_usernames.update(name.text for name in usernames)\n",
        "\n",
        "        print(f\"Collected {len(unique_usernames)} unique usernames\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to fetch the page. Status Code: {response.status_code}\")\n",
        "\n",
        "    # Add a 5-second delay before making the next request\n",
        "    time.sleep(5)\n",
        "\n",
        "# Now you have collected at least 100 unique usernames\n",
        "for username in unique_usernames:\n",
        "    print(username)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l8KL8eRGjiA",
        "outputId": "737fb423-b2da-408d-e091-f16c1b6f61c7"
      },
      "outputs": [],
      "source": [
        "user_list = user_list.append(pd.DataFrame({\"username\": list(unique_usernames)}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OLJswS-HHZRI",
        "outputId": "b3958500-c92b-4fd7-bfd1-191e7eabbcf8"
      },
      "outputs": [],
      "source": [
        "# Export to CSV\n",
        "user_list.to_csv('user_list_11423.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0L3-YCpMXvm"
      },
      "source": [
        "## 1.3 MyAnimeList API Implementation\n",
        "\n",
        "Now that we have a list of users, we can use the MyAnimeList API to fetch each users' anime ratings.\n",
        "- Due to the high volume of data, we chunked every 1,000,000 rows to a CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11k8h8apOdXe"
      },
      "outputs": [],
      "source": [
        "CLIENT_ID = '018269e286b49a7ca078f74376d45377'\n",
        "\n",
        "# Initialize an empty list to store all the data\n",
        "all_user_ratings = []\n",
        "df_user_ratings = pd.DataFrame(columns=['user_id', 'anime_id', 'title', 'user_status', 'user_score', 'user_eps_watched', 'user_rewatch', 'updated_at'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_zbpP-Nrxv6"
      },
      "outputs": [],
      "source": [
        "#read the username list csv\n",
        "user_list_cleaned = pd.read_csv('cleaned/user_list_cleaned_random_10000_2.csv')\n",
        "api_counter = 0\n",
        "list_counter = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOQ_xKSCr0r7",
        "outputId": "831b2714-cfe8-424b-843a-6856000a5fe2"
      },
      "outputs": [],
      "source": [
        "for user_name in user_list_cleaned['username']:\n",
        "  limit = 1000\n",
        "  url = f'https://api.myanimelist.net/v2/users/{user_name}/animelist?fields=id,title,genres,synopsis,list_status&limit={limit}]&nsfw=true'\n",
        "\n",
        "  response = requests.get(url, headers = {\n",
        "      'X-MAL-CLIENT-ID': CLIENT_ID\n",
        "      })\n",
        "\n",
        "  if response.status_code == 403: #check if list is private, skip\n",
        "    print(\"403 user skipped\")\n",
        "    continue\n",
        "  if response.status_code == 404: #if id doesnt exit, skip\n",
        "    print(\"404 user skipped\")\n",
        "    continue\n",
        "\n",
        "  response.raise_for_status()\n",
        "  user_ratings = response.json()\n",
        "  response.close()\n",
        "\n",
        "  all_user_ratings.extend(user_ratings['data'])\n",
        "\n",
        "  user_data = [{\n",
        "      'user_id': user_name,\n",
        "      'anime_id': entry['node']['id'],\n",
        "      'title': entry['node']['title'],\n",
        "      'user_status': entry['list_status'].get('status', '-1'),\n",
        "      'user_score': entry['list_status'].get('score', '-1'),\n",
        "      'user_eps_watched': entry['list_status'].get('num_episodes_watched', '-1'),\n",
        "      'user_rewatch': entry['list_status'].get('is_rewatching', '-1'),\n",
        "      'updated_at': entry['list_status'].get('updated_at','-1')\n",
        "  } for entry in all_user_ratings]\n",
        "\n",
        "# THIS IS FOR CHUNKING DATA\n",
        "  if df_user_ratings.shape[0] > 1000000: #if number of rows exceed 1,000,000 (for excel) export to excel\n",
        "    df_user_ratings.to_csv(f'all_user_ratings_2_{list_counter}.csv', index=False)\n",
        "    list_counter += 1\n",
        "    # Initialize an empty list\n",
        "    all_user_ratings = []\n",
        "    df_user_ratings = pd.DataFrame(columns=['user_id', 'anime_id', 'title', 'user_status', 'user_score', 'user_eps_watched', 'user_rewatch', 'updated_at'])\n",
        "\n",
        "  df_user_ratings = df_user_ratings.append(pd.DataFrame(user_data))\n",
        "  print(\"Appended:\",api_counter, \"users\")\n",
        "  api_counter += 1\n",
        "\n",
        "  time.sleep(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "rYESulYS2Vtp",
        "outputId": "070fac6c-90fb-475e-a3d7-8546d706d285"
      },
      "outputs": [],
      "source": [
        "# Export the DataFrame to a CSV\n",
        "df_user_ratings.to_csv('all_user_ratings_2_124.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATA CLEANING (Part 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Cleaning All Pulled Anime List\n",
        "- Cleaned formatting of columns\n",
        "- Added '_' for readability\n",
        "- Created a dummy variable version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "folder_path = 'appended'\n",
        "combined_data = pd.DataFrame()\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        data = pd.read_csv(file_path)\n",
        "        combined_data = combined_data.append(data, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data = combined_data.sort_values(by='anime_id')\n",
        "combined_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = combined_data.copy()\n",
        "\n",
        "test_df['genres'] = test_df['genres'].apply(lambda x: ''.join([genre.strip(\"[]\") for genre in x]))\n",
        "test_df['studios'] = test_df['studios'].apply(lambda x: ''.join([studios.strip(\"[]\") for studios in x]))\n",
        "\n",
        "test_df['genres'] = test_df['genres'].apply(lambda x: x.replace(\"'\", \"\"))\n",
        "test_df['studios'] = test_df['studios'].apply(lambda x: x.replace(\"'\", \"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df['genres'] = test_df['genres'].str.replace(r'(?<=\\w) (?=\\w)', '_', regex=True)\n",
        "test_df['studios'] = test_df['studios'].str.replace(r'(?<=\\w) (?=\\w)', '_', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df['studios'] = test_df['studios'].replace('', -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_variables_genres = test_df['genres'].str.get_dummies(', ').add_prefix('genre_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_variables_studios = test_df['studios'].str.get_dummies(', ').add_prefix('studio_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = pd.concat([test_df, dummy_variables_genres], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = pd.concat([test_df, dummy_variables_studios], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the combined data to a new CSV file or perform further processing\n",
        "test_df.to_csv('all_anime_list_cleaned_with_dummies.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Cleaning Username List\n",
        "- Appended all the username CSVs our team created\n",
        "- Cleaned the lists to remove duplicates and NA values\n",
        "- Due to the large number of usernames, we decided it was not feasible to include all 70k usernames we scraped\n",
        "- Randomly selected 10k usernames from our data\n",
        "- After running the model, it seemed like this sample size was too small\n",
        "- Thus, we randomly selected another 10k usernames (hence the 2 seperate instances of sampled_df) [20k usernames in total]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "folder_path = 'user lists'\n",
        "combined_data = pd.DataFrame()\n",
        "\n",
        "#read folder with all username lists and append them\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        data = pd.read_csv(file_path)\n",
        "        combined_data = combined_data.append(data, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#drop any duplicates, NA, and sort \n",
        "combined_data = combined_data.drop_duplicates(subset='username')\n",
        "combined_data = combined_data.dropna(subset=['username'])\n",
        "combined_data = combined_data.sort_values(by='username')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data.to_csv('user_list_cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Randomly select x amount of usernames\n",
        "sampled_df = combined_data.sample(n=10000, random_state=12) \n",
        "sampled_df.reset_index(drop=True, inplace=True)\n",
        "sampled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampled_df.to_csv('user_list_cleaned_random_10000.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for more usernames\n",
        "orig_user_list = pd.read_csv('cleaned/user_list_cleaned.csv')\n",
        "random_10k = pd.read_csv('cleaned/user_list_cleaned_random_10000.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orig_user_list = orig_user_list[~orig_user_list['username'].isin(random_10k['username'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Randomly select x amount of usernames\n",
        "sampled_df = orig_user_list.sample(n=10000, random_state=12)\n",
        "sampled_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampled_df.to_csv('user_list_cleaned_random_10000_2.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.3 Cleaning User Ratings and Chunking\n",
        "- Chunked the user ratings into seperate folders\n",
        "- Combined all user ratings in each folder into 1 chunked dataframe (5 chunks by the end)\n",
        "- Dropped NA, dropped duplicates\n",
        "- Removed rows with missing data (-1)\n",
        "- Removed shows that were not watched yet (only kept Completed and Dropped shows)\n",
        "- Assumed \"0\" rating meant the show was not watched\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#store each user rating csvs in seperate chunked folders\n",
        "folder_path = 'anime_user_ratings/chunk_5'\n",
        "combined_data = pd.DataFrame()\n",
        "file_count = 0\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        data = pd.read_csv(file_path)\n",
        "        combined_data = combined_data.append(data, ignore_index=True)\n",
        "        file_count += 1\n",
        "        print(file_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data = combined_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data = combined_data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#remove all rows that contain -1\n",
        "mask = (combined_data['user_status'] != -1) & (combined_data['user_score'] != -1) & (combined_data['user_eps_watched'] != -1) & (combined_data['user_rewatch'] != -1) & (combined_data['updated_at'] != -1)\n",
        "filtered_combined_data = combined_data[mask]\n",
        "filtered_combined_data.reset_index(drop=True, inplace=True)\n",
        "filtered_combined_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#remove all rows that are animes that users havent watched\n",
        "filtered_df = filtered_combined_data[(filtered_combined_data['user_status'] != 'plan_to_watch')]\n",
        "filtered_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#remove all rows where user rating is 0 - assumes this means they did not rate it\n",
        "filtered_df = filtered_df[~(filtered_df['user_score'] == 0)]\n",
        "filtered_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for counting how many unique usernames in data\n",
        "unique_usernames_count = filtered_df['user_id'].nunique()\n",
        "unique_usernames_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_df.to_csv('anime_user_ratings_2_chunk_5.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.4 One More User Rating Cleaning...\n",
        "- Discovered discrepancy in the user ratings\n",
        "- Users had multiple ratings for the same shows (site tracks every instance where a user rates a show)\n",
        "- Decided to only keep the most updated rating of show for each user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "folder_path = 'cleaned/anime_user_ratings_chunked_2'\n",
        "combined_data = pd.DataFrame()\n",
        "file_count = 0\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        data = pd.read_csv(file_path)\n",
        "        combined_data = combined_data.append(data, ignore_index=True)\n",
        "        file_count += 1\n",
        "        print(file_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data['updated_at'] = pd.to_datetime(combined_data['updated_at'])\n",
        "combined_data = combined_data.sort_values(by='updated_at', ascending=False)\n",
        "combined_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_no_duplicates = combined_data.drop_duplicates(subset=['user_id', 'anime_id'], keep='first')\n",
        "df_no_duplicates.reset_index(drop=True, inplace=True)\n",
        "df_no_duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test3 = (df_no_duplicates[(df_no_duplicates['anime_id'] == 1)])\n",
        "test3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_usernames_count = df_no_duplicates['user_id'].nunique()\n",
        "unique_usernames_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test3.to_csv('test3.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_no_duplicates.to_csv('anime_user_ratings_cleaned_full_2.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MACHINE LEARNING MODEL (Part 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 KNN Model to predict Anime Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# read the user ratings\n",
        "user_ratings = pd.read_csv('cleaned/anime_user_ratings_cleaned_final.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a user-item matrix with anime_id as rows, user_id as columns, and ratings as values.\n",
        "user_item_matrix = user_ratings.pivot_table(index='anime_id', columns='user_id', values='user_score', fill_value=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "NearestNeighbors(algorithm='brute', metric='cosine')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize and fit the KNN model\n",
        "knn_model = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\n",
        "knn_model.fit(user_item_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a DataFrame with anime titles\n",
        "anime_data = pd.read_csv('cleaned/all_anime_list_cleaned_1_52000.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andrewgatchalian/anaconda3/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>studios</th>\n",
              "      <th>synopsis</th>\n",
              "      <th>media_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16148</th>\n",
              "      <td>Kaguya-sama wa Kokurasetai? Tensai-tachi no Re...</td>\n",
              "      <td>Comedy, Psychological, Romantic Subtext, Schoo...</td>\n",
              "      <td>A-1 Pictures</td>\n",
              "      <td>After a slow but eventful summer vacation, Shu...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17202</th>\n",
              "      <td>Horimiya</td>\n",
              "      <td>Romance, School, Shounen</td>\n",
              "      <td>CloverWorks</td>\n",
              "      <td>On the surface, the thought of Kyouko Hori and...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17574</th>\n",
              "      <td>Kaguya-sama wa Kokurasetai: Ultra Romantic</td>\n",
              "      <td>Comedy, Romance, School, Seinen</td>\n",
              "      <td>A-1 Pictures</td>\n",
              "      <td>The elite members of Shuchiin Academy's studen...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "16148  Kaguya-sama wa Kokurasetai? Tensai-tachi no Re...   \n",
              "17202                                           Horimiya   \n",
              "17574         Kaguya-sama wa Kokurasetai: Ultra Romantic   \n",
              "\n",
              "                                                  genres       studios  \\\n",
              "16148  Comedy, Psychological, Romantic Subtext, Schoo...  A-1 Pictures   \n",
              "17202                           Romance, School, Shounen   CloverWorks   \n",
              "17574                    Comedy, Romance, School, Seinen  A-1 Pictures   \n",
              "\n",
              "                                                synopsis media_type  \n",
              "16148  After a slow but eventful summer vacation, Shu...         tv  \n",
              "17202  On the surface, the thought of Kyouko Hori and...         tv  \n",
              "17574  The elite members of Shuchiin Academy's studen...         tv  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose the target anime for which you want to make recommendations\n",
        "target_anime_id = 40839 # Replace with the desired anime_id\n",
        "\n",
        "# Locate the target anime's column in the user-item matrix\n",
        "target_anime_row = user_item_matrix.loc[target_anime_id].values.reshape(1, -1)\n",
        "\n",
        "# Find the nearest neighbors for the target anime\n",
        "distances, neighbor_indices = knn_model.kneighbors(target_anime_row)\n",
        "\n",
        "# Recommend animes based on the nearest neighbors\n",
        "recommended_anime_ids = user_item_matrix.index[neighbor_indices.flatten()]\n",
        "\n",
        "# Exclude the target anime from recommendations\n",
        "recommended_anime_ids = [anime_id for anime_id in recommended_anime_ids if anime_id != target_anime_id]\n",
        "\n",
        "# Lookup the titles of the recommended animes\n",
        "recommended_anime_titles = anime_data.loc[anime_data['anime_id'].isin(recommended_anime_ids)]\n",
        "\n",
        "recommended_anime_info = pd.DataFrame(recommended_anime_titles[['title', 'genres','studios','synopsis','media_type']])\n",
        "\n",
        "# Print recommended anime titles\n",
        "recommended_anime_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Let's try Z-score normalization to improve accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Z-score normalization for each column (anime)\n",
        "standardized_item_matrix = (user_item_matrix - user_item_matrix.mean(axis=0)) / user_item_matrix.std(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "NearestNeighbors(algorithm='brute', metric='cosine')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize and fit the KNN model\n",
        "knn_model2 = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\n",
        "knn_model2.fit(standardized_item_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andrewgatchalian/anaconda3/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>studios</th>\n",
              "      <th>synopsis</th>\n",
              "      <th>media_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14558</th>\n",
              "      <td>Kaguya-sama wa Kokurasetai: Tensai-tachi no Re...</td>\n",
              "      <td>Comedy, Psychological, Romantic Subtext, Schoo...</td>\n",
              "      <td>A-1 Pictures</td>\n",
              "      <td>At the renowned Shuchiin Academy, Miyuki Shiro...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15707</th>\n",
              "      <td>5-toubun no Hanayome âˆ¬</td>\n",
              "      <td>Comedy, Harem, Romance, School, Shounen</td>\n",
              "      <td>Bibury Animation Studios</td>\n",
              "      <td>Through their tutor Fuutarou Uesugi's diligent...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16148</th>\n",
              "      <td>Kaguya-sama wa Kokurasetai? Tensai-tachi no Re...</td>\n",
              "      <td>Comedy, Psychological, Romantic Subtext, Schoo...</td>\n",
              "      <td>A-1 Pictures</td>\n",
              "      <td>After a slow but eventful summer vacation, Shu...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17234</th>\n",
              "      <td>Kanojo, Okarishimasu 2nd Season</td>\n",
              "      <td>Adult Cast, Comedy, Harem, Romance, Shounen</td>\n",
              "      <td>TMS Entertainment</td>\n",
              "      <td>A year after they met, Kazuya Kinoshita and Ch...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "14558  Kaguya-sama wa Kokurasetai: Tensai-tachi no Re...   \n",
              "15707                             5-toubun no Hanayome âˆ¬   \n",
              "16148  Kaguya-sama wa Kokurasetai? Tensai-tachi no Re...   \n",
              "17234                    Kanojo, Okarishimasu 2nd Season   \n",
              "\n",
              "                                                  genres  \\\n",
              "14558  Comedy, Psychological, Romantic Subtext, Schoo...   \n",
              "15707            Comedy, Harem, Romance, School, Shounen   \n",
              "16148  Comedy, Psychological, Romantic Subtext, Schoo...   \n",
              "17234        Adult Cast, Comedy, Harem, Romance, Shounen   \n",
              "\n",
              "                        studios  \\\n",
              "14558              A-1 Pictures   \n",
              "15707  Bibury Animation Studios   \n",
              "16148              A-1 Pictures   \n",
              "17234         TMS Entertainment   \n",
              "\n",
              "                                                synopsis media_type  \n",
              "14558  At the renowned Shuchiin Academy, Miyuki Shiro...         tv  \n",
              "15707  Through their tutor Fuutarou Uesugi's diligent...         tv  \n",
              "16148  After a slow but eventful summer vacation, Shu...         tv  \n",
              "17234  A year after they met, Kazuya Kinoshita and Ch...         tv  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose the target anime for which you want to make recommendations\n",
        "target_anime_id = 40839 # Replace with the desired anime_id\n",
        "\n",
        "# Locate the target anime's column in the user-item matrix\n",
        "target_anime_row = standardized_item_matrix.loc[target_anime_id].values.reshape(1, -1)\n",
        "\n",
        "# Find the nearest neighbors for the target anime\n",
        "distances, neighbor_indices = knn_model2.kneighbors(target_anime_row)\n",
        "\n",
        "# Recommend animes based on the nearest neighbors\n",
        "recommended_anime_ids = standardized_item_matrix.index[neighbor_indices.flatten()]\n",
        "\n",
        "# Exclude the target anime from recommendations\n",
        "recommended_anime_ids = [anime_id for anime_id in recommended_anime_ids if anime_id != target_anime_id]\n",
        "\n",
        "# Lookup the titles of the recommended animes\n",
        "recommended_anime_titles = anime_data.loc[anime_data['anime_id'].isin(recommended_anime_ids)]\n",
        "\n",
        "recommended_anime_info = pd.DataFrame(recommended_anime_titles[['title', 'genres','studios','synopsis','media_type']])\n",
        "\n",
        "# Print recommended anime titles\n",
        "recommended_anime_info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 Adding Genres as Dummy Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load genre dummy variables\n",
        "knn_genres = pd.read_csv('cleaned/knn_genres.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#merge previous standardized item matrix with dummies\n",
        "merged_df = pd.merge(standardized_item_matrix, knn_genres, on='anime_id', how='inner')\n",
        "standardized_item_matrix2 = merged_df.set_index('anime_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "NearestNeighbors(algorithm='brute', metric='cosine')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize and fit the KNN model\n",
        "knn_model3 = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\n",
        "knn_model3.fit(standardized_item_matrix2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andrewgatchalian/anaconda3/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>studios</th>\n",
              "      <th>synopsis</th>\n",
              "      <th>media_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14558</th>\n",
              "      <td>Kaguya-sama wa Kokurasetai: Tensai-tachi no Re...</td>\n",
              "      <td>Comedy, Psychological, Romantic Subtext, Schoo...</td>\n",
              "      <td>A-1 Pictures</td>\n",
              "      <td>At the renowned Shuchiin Academy, Miyuki Shiro...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15707</th>\n",
              "      <td>5-toubun no Hanayome âˆ¬</td>\n",
              "      <td>Comedy, Harem, Romance, School, Shounen</td>\n",
              "      <td>Bibury Animation Studios</td>\n",
              "      <td>Through their tutor Fuutarou Uesugi's diligent...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16148</th>\n",
              "      <td>Kaguya-sama wa Kokurasetai? Tensai-tachi no Re...</td>\n",
              "      <td>Comedy, Psychological, Romantic Subtext, Schoo...</td>\n",
              "      <td>A-1 Pictures</td>\n",
              "      <td>After a slow but eventful summer vacation, Shu...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17234</th>\n",
              "      <td>Kanojo, Okarishimasu 2nd Season</td>\n",
              "      <td>Adult Cast, Comedy, Harem, Romance, Shounen</td>\n",
              "      <td>TMS Entertainment</td>\n",
              "      <td>A year after they met, Kazuya Kinoshita and Ch...</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "14558  Kaguya-sama wa Kokurasetai: Tensai-tachi no Re...   \n",
              "15707                             5-toubun no Hanayome âˆ¬   \n",
              "16148  Kaguya-sama wa Kokurasetai? Tensai-tachi no Re...   \n",
              "17234                    Kanojo, Okarishimasu 2nd Season   \n",
              "\n",
              "                                                  genres  \\\n",
              "14558  Comedy, Psychological, Romantic Subtext, Schoo...   \n",
              "15707            Comedy, Harem, Romance, School, Shounen   \n",
              "16148  Comedy, Psychological, Romantic Subtext, Schoo...   \n",
              "17234        Adult Cast, Comedy, Harem, Romance, Shounen   \n",
              "\n",
              "                        studios  \\\n",
              "14558              A-1 Pictures   \n",
              "15707  Bibury Animation Studios   \n",
              "16148              A-1 Pictures   \n",
              "17234         TMS Entertainment   \n",
              "\n",
              "                                                synopsis media_type  \n",
              "14558  At the renowned Shuchiin Academy, Miyuki Shiro...         tv  \n",
              "15707  Through their tutor Fuutarou Uesugi's diligent...         tv  \n",
              "16148  After a slow but eventful summer vacation, Shu...         tv  \n",
              "17234  A year after they met, Kazuya Kinoshita and Ch...         tv  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose the target anime for which you want to make recommendations\n",
        "target_anime_id = 40839 # Replace with the desired anime_id\n",
        "\n",
        "# Locate the target anime's column in the user-item matrix\n",
        "target_anime_row = standardized_item_matrix2.loc[target_anime_id].values.reshape(1, -1)\n",
        "\n",
        "# Find the nearest neighbors for the target anime\n",
        "distances, neighbor_indices = knn_model3.kneighbors(target_anime_row)\n",
        "\n",
        "# Recommend animes based on the nearest neighbors\n",
        "recommended_anime_ids = standardized_item_matrix2.index[neighbor_indices.flatten()]\n",
        "\n",
        "# Exclude the target anime from recommendations\n",
        "recommended_anime_ids = [anime_id for anime_id in recommended_anime_ids if anime_id != target_anime_id]\n",
        "\n",
        "# Lookup the titles of the recommended animes\n",
        "recommended_anime_titles = anime_data.loc[anime_data['anime_id'].isin(recommended_anime_ids)]\n",
        "\n",
        "recommended_anime_info = pd.DataFrame(recommended_anime_titles[['title', 'genres','studios','synopsis','media_type']])\n",
        "\n",
        "# Print recommended anime titles\n",
        "recommended_anime_info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results:\n",
        "\n",
        "target id: 38000 (Demon Slayer) - Popular Anime\n",
        "model 1:\n",
        "7430\tShingeki no Kyojin\tAction, Award Winning, Drama, Gore, Military, ...\tWit Studio\tCenturies ago, mankind was slaughtered to near...\ttv\n",
        "13198\tShingeki no Kyojin Season 3\tAction, Drama, Gore, Military, Shounen, Survival\tWit Studio\tStill threatened by the \"Titans\" that rob them...\ttv\n",
        "16068\tKimetsu no Yaiba Movie: Mugen Ressha-hen\tAction, Fantasy, Historical, Shounen\tufotable\tAfter a string of mysterious disappearances be...\tmovie\n",
        "20429\tKimetsu no Yaiba: Yuukaku-hen\tAction, Fantasy, Historical, Shounen\tufotable\tThe devastation of the Mugen Train incident st...\ttv\n",
        "\n",
        "- Recommendation did not change in each model\n",
        "- Seems like very popular shows are not affected by the changes\n",
        "\n",
        "target id: 33206 (Kobayashi Dragon Maid) - Semi Popular Anime\n",
        "\n",
        "model 1:\n",
        "title\tgenres\tstudios\tsynopsis\tmedia_type\n",
        "14240\tMob Psycho 100 II\tAction, Comedy, Super Power, Supernatural\tBones\tShigeo \"Mob\" Kageyama is now maturing and unde...\ttv\n",
        "15376\tKobayashi-san Chi no Maid Dragon S\tFantasy, Slice of Life\tKyoto Animation\tAs Tooru continues on her quest to become the ...\ttv\n",
        "16148\tKaguya-sama wa Kokurasetai? Tensai-tachi no Re...\tComedy, Psychological, Romantic Subtext, Schoo...\tA-1 Pictures\tAfter a slow but eventful summer vacation, Shu...\ttv\n",
        "17574\tKaguya-sama wa Kokurasetai: Ultra Romantic\tComedy, Romance, School, Seinen\tA-1 Pictures\tThe elite members of Shuchiin Academy's studen...\ttv\n",
        "\n",
        "model 2:\n",
        "title\tgenres\tstudios\tsynopsis\tmedia_type\n",
        "10629\tKono Subarashii Sekai ni Shukufuku wo!\tAdventure, Comedy, Fantasy, Isekai, Parody, Re...\tStudio Deen\tAfter dying a laughable and pathetic death on ...\ttv\n",
        "11596\tKono Subarashii Sekai ni Shukufuku wo! 2\tAdventure, Comedy, Fantasy, Isekai, Parody, Re...\tStudio Deen\tWhen Kazuma Satou died, he was given two choic...\ttv\n",
        "14598\tKono Subarashii Sekai ni Shukufuku wo! Movie: ...\tAdventure, Comedy, Fantasy, Isekai, Parody, Re...\tJ.C.Staff\tIt is not strange that the Demon Lord's forces...\tmovie\n",
        "15376\tKobayashi-san Chi no Maid Dragon S\tFantasy, Slice of Life\tKyoto Animation\tAs Tooru continues on her quest to become the ...\ttv\n",
        "\n",
        "model 3:\n",
        "title\tgenres\tstudios\tsynopsis\tmedia_type\n",
        "10629\tKono Subarashii Sekai ni Shukufuku wo!\tAdventure, Comedy, Fantasy, Isekai, Parody, Re...\tStudio Deen\tAfter dying a laughable and pathetic death on ...\ttv\n",
        "11596\tKono Subarashii Sekai ni Shukufuku wo! 2\tAdventure, Comedy, Fantasy, Isekai, Parody, Re...\tStudio Deen\tWhen Kazuma Satou died, he was given two choic...\ttv\n",
        "14598\tKono Subarashii Sekai ni Shukufuku wo! Movie: ...\tAdventure, Comedy, Fantasy, Isekai, Parody, Re...\tJ.C.Staff\tIt is not strange that the Demon Lord's forces...\tmovie\n",
        "15376\tKobayashi-san Chi no Maid Dragon S\tFantasy, Slice of Life\tKyoto Animation\tAs Tooru continues on her quest to become the ...\ttv\n",
        "\n",
        "- Recommendation did not change after model 2\n",
        "- Genre may not significantly effect the neighbors\n",
        "- Model 2 generates a more accurate recommendation\n",
        "\n",
        "target id: 16417 (Tamako Market) - Below average popularity\n",
        "\n",
        "model 1:\n",
        "\ttitle\tgenres\tstudios\tsynopsis\tmedia_type\n",
        "4956\tSuzumiya Haruhi no Shoushitsu\tAward Winning, Mystery, School, Sci-Fi, Supern...\tKyoto Animation\tOn a cold December day, Kyon arrives at school...\tmovie\n",
        "8474\tTamako Love Story\tAward Winning, Romance, Slice of Life\tKyoto Animation\tAs the seasons pass by, the end of Mochizou Oo...\tmovie\n",
        "12582\tYuru Campâ–³\tCGDCT, Iyashikei, Slice of Life\tC-Station\tWhile the perfect getaway for most girls her a...\ttv\n",
        "13982\tViolet Evergarden: Kitto \"Ai\" wo Shiru Hi ga K...\tDrama, Fantasy\tKyoto Animation\tThe CH Postal Company has just received a requ...\tspecial\n",
        "\n",
        "model 2:\n",
        "title\tgenres\tstudios\tsynopsis\tmedia_type\n",
        "4956\tSuzumiya Haruhi no Shoushitsu\tAward Winning, Mystery, School, Sci-Fi, Supern...\tKyoto Animation\tOn a cold December day, Kyon arrives at school...\tmovie\n",
        "8474\tTamako Love Story\tAward Winning, Romance, Slice of Life\tKyoto Animation\tAs the seasons pass by, the end of Mochizou Oo...\tmovie\n",
        "9651\tHibike! Euphonium\tDrama, Music, Performing Arts, School\tKyoto Animation\tNow that Kumiko Oumae has enrolled in Kitauji ...\ttv\n",
        "12582\tYuru Campâ–³\tCGDCT, Iyashikei, Slice of Life\tC-Station\tWhile the perfect getaway for most girls her a...\ttv\n",
        "\n",
        "model 3:\n",
        "title\tgenres\tstudios\tsynopsis\tmedia_type\n",
        "4956\tSuzumiya Haruhi no Shoushitsu\tAward Winning, Mystery, School, Sci-Fi, Supern...\tKyoto Animation\tOn a cold December day, Kyon arrives at school...\tmovie\n",
        "8474\tTamako Love Story\tAward Winning, Romance, Slice of Life\tKyoto Animation\tAs the seasons pass by, the end of Mochizou Oo...\tmovie\n",
        "9651\tHibike! Euphonium\tDrama, Music, Performing Arts, School\tKyoto Animation\tNow that Kumiko Oumae has enrolled in Kitauji ...\ttv\n",
        "12582\tYuru Campâ–³\tCGDCT, Iyashikei, Slice of Life\tC-Station\tWhile the perfect getaway for most girls her a...\ttv\n",
        "\n",
        "- Model 2 indicates that the z-score normalization does help with accuracy\n",
        "\n",
        "target id: 47 (Akira) - Let's see if being a movie affects recommendations\n",
        "\n",
        "model 1:\n",
        "title\tgenres\tstudios\tsynopsis\tmedia_type\n",
        "0\tCowboy Bebop\tAction, Adult Cast, Award Winning, Sci-Fi, Space\tSunrise\tCrime is timeless. By the year 2071, humanity ...\ttv\n",
        "142\tMononoke Hime\tAction, Adventure, Award Winning, Fantasy\tStudio Ghibli\tWhen an Emishi village is attacked by a fierce...\tmovie\n",
        "409\tPerfect Blue\tAdult Cast, Avant Garde, Drama, Horror, Psycho...\tMadhouse\tJ-pop idol group CHAM! has spent the last two ...\tmovie\n",
        "14240\tMob Psycho 100 II\tAction, Comedy, Super Power, Supernatural\tBones\tShigeo \"Mob\" Kageyama is now maturing and unde...\ttv\n",
        "\n",
        "model 2:\n",
        "title\tgenres\tstudios\tsynopsis\tmedia_type\n",
        "0\tCowboy Bebop\tAction, Adult Cast, Award Winning, Sci-Fi, Space\tSunrise\tCrime is timeless. By the year 2071, humanity ...\ttv\n",
        "24\tKoukaku Kidoutai\tAction, Adult Cast, Award Winning, Detective, ...\tProduction I.G\tIn the year 2029, Niihama City has become a te...\tmovie\n",
        "142\tMononoke Hime\tAction, Adventure, Award Winning, Fantasy\tStudio Ghibli\tWhen an Emishi village is attacked by a fierce...\tmovie\n",
        "409\tPerfect Blue\tAdult Cast, Avant Garde, Drama, Horror, Psycho...\tMadhouse\tJ-pop idol group CHAM! has spent the last two ...\tmovie\n",
        "\n",
        "model 3:\n",
        "title\tgenres\tstudios\tsynopsis\tmedia_type\n",
        "0\tCowboy Bebop\tAction, Adult Cast, Award Winning, Sci-Fi, Space\tSunrise\tCrime is timeless. By the year 2071, humanity ...\ttv\n",
        "24\tKoukaku Kidoutai\tAction, Adult Cast, Award Winning, Detective, ...\tProduction I.G\tIn the year 2029, Niihama City has become a te...\tmovie\n",
        "142\tMononoke Hime\tAction, Adventure, Award Winning, Fantasy\tStudio Ghibli\tWhen an Emishi village is attacked by a fierce...\tmovie\n",
        "409\tPerfect Blue\tAdult Cast, Avant Garde, Drama, Horror, Psycho...\tMadhouse\tJ-pop idol group CHAM! has spent the last two ...\tmovie\n",
        "\n",
        "- Model 2 recommends \"Koukaku Kidoutai\" in place of \"Mob Psycho\" which can objectively be seen as a more accurate recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions\n",
        "\n",
        "- Z-score normalization seems to improve the accuracy of our model\n",
        "- Genre does not seem have a significant effect due to the nature of our model\n",
        "- Extremely popular shows with large numbers of rating may have more stable and dense neighbors, meaning with each iteration of the model, the neighbors will remain relatively similar\n",
        "- In contrast, mid-low level popularity shows are more sensitive to changes (normalization)\n",
        "\n",
        "## What our results tell us about the data?\n",
        "- Achieving some level of accuracy from our recommendations indicate a consistency or pattern for how users rate anime shows\n",
        "- Users who give similar ratings to shows tend to have somewhat similar preferences\n",
        "- KNN model uses these similarities to recommend a show that other users with similar taste have enjoyed\n",
        "- Ex. if a user enjoys romance anime, nearby neighbors in the model may be in the romance genre\n",
        "\n",
        "## Limitations and Future Applications\n",
        "- Due to the time constraints and memory allocation, our model is limited by sample size (18k users)\n",
        "- Model can be improved by increasing our training data\n",
        "- Incorporate other features such as \"drop/complete\", \"studio\", \"num of eps\", etc.\n",
        "- Model can be applied to \"users\" instead of \"anime id\", recommend shows based on other users who have similar taste"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
